{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Jane-Street-Market-NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoGranja/Jane-Street-Market-NN/blob/main/Jane_Street_Market_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnQWrKupGEAD"
      },
      "source": [
        "Download Dataset and install needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fug7eGzTzLbg"
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuyB7Otxz_f1",
        "outputId": "32fb0618-a1f3-4ea7-a66f-68958aa1a25d"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#Package Installation\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp drive/MyDrive/colab/kaggle.json ~/.kaggle/kaggle.json\n",
        "#!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: kaggle 1.5.6\n",
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.3)\n",
            "Collecting kaggle==1.5.6\n",
            "  Using cached kaggle-1.5.6-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.8.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2020.12.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.10)\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzRAHp9mAPFs"
      },
      "source": [
        "#! kaggle competitions list"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIPW-nChHIpg",
        "outputId": "55b541be-974c-4744-c178-1aa0490c0ca0"
      },
      "source": [
        "!kaggle competitions download -c 'jane-street-market-prediction'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading jane-street-market-prediction.zip to /content\n",
            "100% 2.63G/2.63G [00:40<00:00, 47.0MB/s]\n",
            "100% 2.63G/2.63G [00:40<00:00, 70.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbZnwpYmgUD0",
        "outputId": "559018c6-823c-4c9a-a502-a7ee4ba158f4"
      },
      "source": [
        "! mkdir model\n",
        "\n",
        "#! kaggle datasets download -d 'granja/restnet50modelstatewithyaw'\n",
        "#! unzip restnet50modelstatewithyaw.zip -d model\n",
        "\n",
        "! unzip jane-street-market-prediction.zip\n",
        "%rm -r jane-street-market-prediction.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘model’: File exists\n",
            "Archive:  jane-street-market-prediction.zip\n",
            "replace example_sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk78b8REzLbl"
      },
      "source": [
        "# Imports\n",
        "import time, os, random\n",
        "from typing import Dict\n",
        "import gc\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tempfile import gettempdir\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from prettytable import PrettyTable\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision.models.resnet import resnet50, resnet34\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import TensorDataset, Dataset\n",
        "#from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler, minmax_scale\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJpJriwjzLbo"
      },
      "source": [
        "# **Configuration**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve2vgeG3zLbp"
      },
      "source": [
        "dataset_path='/content/train.csv'\n",
        "\n",
        "cfg = {\n",
        "    'model_params': {\n",
        "        'model_architecture': 'nn',\n",
        "        'model_name': \"nn_output\",\n",
        "        'n_hidden': 512,\n",
        "        'n_layers': 2,\n",
        "        'lr': 1e-3,\n",
        "        'weight_path': 'drive/MyDrive/colab/nn_model_state_9999.pth',\n",
        "        'train': True,\n",
        "        'validate': False\n",
        "    },\n",
        "\n",
        "    'train_params': {\n",
        "        'max_num_steps': 10000,\n",
        "        'checkpoint_every_n_steps': 2000,\n",
        "        'batch_size': 4096,\n",
        "        'valid_split': 0.1,\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP9_nd8QTB0Z"
      },
      "source": [
        "def seed_everything(seed=42):\r\n",
        "    random.seed(seed)\r\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "seed_everything(seed=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9i_voo8zLbs"
      },
      "source": [
        "# **Loading the cleaning data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Kf-ACtzLbt",
        "outputId": "a705052c-10be-4815-e088-b2e52dba8c47"
      },
      "source": [
        "# Import dataset as train\n",
        "train = pd.read_csv(dataset_path) #, nrows=200000)\n",
        "train.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2390491 entries, 0 to 2390490\n",
            "Columns: 138 entries, date to ts_id\n",
            "dtypes: float64(135), int64(3)\n",
            "memory usage: 2.5 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmw91KsuSFq0"
      },
      "source": [
        "#train.describe()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN9h7BaSdMCM"
      },
      "source": [
        "#train['date'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzbq4x-Fdu3J"
      },
      "source": [
        "#train['weight'].hist()\n",
        "#plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWAeVNY9Ncgp"
      },
      "source": [
        "\n",
        "features = [col for col in list(train.columns) if 'feature' in col]\n",
        "train = train.query('weight > 0').reset_index(drop = True)\n",
        "train_mean = train[features].mean()\n",
        "train[features] = train[features].fillna(method = 'ffill').fillna(train_mean)\n",
        "train['action'] = (train['resp'] > 0).astype('int')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjDlF_IpPKun"
      },
      "source": [
        "**Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "OgqK5L6nPHoe",
        "outputId": "bb7f354b-3e60-4eb2-f95d-c430746e4466"
      },
      "source": [
        "# First, we want to check if the target class is balanced or unbalanced in the training data\n",
        "sns.set_palette(\"colorblind\")\n",
        "ax = sns.barplot(train['action'].value_counts().index, train['action'].value_counts()/len(train))\n",
        "ax.set_title(\"Proportion of trades with action=0 and action=1\")\n",
        "ax.set_ylabel(\"Percentage\")\n",
        "ax.set_xlabel(\"Action\")\n",
        "sns.despine();\n",
        "# Target class is fairly balanced with almost 50% of trades corresponding to each action"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGj7vAh7Q3i1"
      },
      "source": [
        "**Features Correlation**\n",
        "\n",
        "We are going to investigate the correlation between all fetures of the dataset. In case strong correlation exists, we can apply a Principle Component Analysis to reduze the dimensionality of this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbx44wE5QbRD"
      },
      "source": [
        "heatmap = False\n",
        "if heatmap:\n",
        "  # Set up the matplotlib figure\n",
        "  f, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "  # Compute the correlation matrix\n",
        "  corr = train_features.corr()\n",
        "\n",
        "  # Draw the heatmap with the mask and correct aspect ratio\n",
        "  sns.heatmap(corr, vmin=-1, vmax=1, center=0,\n",
        "              square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4qduurXRNkD"
      },
      "source": [
        "**Feature Preprocessing:** imputation, scaling, and constructing new features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq8LgpEsT2MG"
      },
      "source": [
        "#Scaling\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train[features])\n",
        "X_train_norm = pd.DataFrame(scaler.transform(train[features]))\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvHhqUpZT2s-"
      },
      "source": [
        "#constructing new features"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4hIgjXjRZMQ"
      },
      "source": [
        "**Feature selection:** dimensionality reduction, to select the best subset of our current set of features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZc68CxqW9fd"
      },
      "source": [
        "PCA = False\n",
        "if PCA:\n",
        "  pca = PCA()\n",
        "  comp = pca.fit(X_train_norm)\n",
        "\n",
        "  # We plot a graph to show how the explained variation in the 129 features varies with the number of principal components\n",
        "  plt.plot(np.cumsum(comp.explained_variance_ratio_))\n",
        "  plt.grid()\n",
        "  plt.xlabel('Number of Principal Components')\n",
        "  plt.ylabel('Explained Variance')\n",
        "  sns.despine();\n",
        "\n",
        "  # The first 15 principal components explains about 80% of the variation\n",
        "  # The first 40 principal components explains about 95% of the variation"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vhgZRHpZHoy"
      },
      "source": [
        "if PCA:\n",
        "  # Using the first 40 principal components, we apply the PCA mapping on both the training and test set\n",
        "  pca = PCA(n_components=40).fit(X_train_norm)\n",
        "  X_train_transform = pca.transform(X_train_norm)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyj1U8KZYtmr"
      },
      "source": [
        "class data(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjNEcYdKPQxH",
        "outputId": "35795d95-1f77-4080-a4ee-24765a7f7337"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_norm, train['action'], test_size=cfg[\"train_params\"][\"valid_split\"], random_state=42)\n",
        "\n",
        "torch_train_target = torch.tensor(y_train.values.astype(np.float32))\n",
        "torch_train_features = torch.tensor(X_train.values.astype(np.float32)) \n",
        "  \n",
        "torch_train_data = data(torch_train_features, torch_train_target)\n",
        "train_dataloader = DataLoader(dataset = torch_train_data, batch_size = cfg[\"train_params\"][\"batch_size\"], shuffle = True)\n",
        "\n",
        "del X_train, y_train, train \n",
        "\n",
        "print(len(train_dataloader))\n",
        "\n",
        "torch_valid_target = torch.tensor(y_valid.values.astype(np.float32))\n",
        "torch_valid_features = torch.tensor(X_valid.values.astype(np.float32)) \n",
        "  \n",
        "torch_valid_data = data(torch_valid_features, torch_valid_target)\n",
        "valid_dataloader = DataLoader(dataset = torch_valid_data, batch_size = cfg[\"train_params\"][\"batch_size\"], shuffle = True)\n",
        "\n",
        "print(len(valid_dataloader))\n",
        "\n",
        "del y_valid,  X_valid"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "436\n",
            "49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdWeB6Y68EVM"
      },
      "source": [
        "def binary_acc(y_pred, y_test):\n",
        "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
        "    acc = correct_results_sum/y_test.shape[0]\n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B44MAMFZRbRZ"
      },
      "source": [
        "**Model Selection:** evaluating many machine learning models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qo7X2EJ8_h9"
      },
      "source": [
        "# define the CNN architecture\n",
        "class JSMCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(JSMCNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(130, 1000)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(1000)\n",
        "        self.fc2 = nn.Linear(1000, 500)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(500)\n",
        "        self.fc3 = nn.Linear(500, 100)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(100)\n",
        "        self.fc_out = nn.Linear(100, 1)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74XR73yQGKsU"
      },
      "source": [
        "class JSMRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, features_len, n_hidden=256, n_layers=2, drop_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        \n",
        "        ## LSTM definition\n",
        "        self.lstm = nn.LSTM(features_len, n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        ## Dropout layer definition \n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        ## Final, fully-connected output layer definition\n",
        "        self.fc = nn.Linear(n_hidden, 1)\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "                \n",
        "        ## Get the outputs and the new hidden state from the lstm\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        ## Pass through a dropout layer\n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "        # Stack up LSTM outputs using view\n",
        "        # you may need to use contiguous to reshape the output\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "        ## Put x through the fully-connected layer\n",
        "        out = F.sigmoid(self.fc(out))\n",
        "        \n",
        "        # return the final output and the hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (torch.cuda.is_available()):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden   "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGOhlFHubFkI"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKL_-KTjNPBj"
      },
      "source": [
        "#Instantiate model\n",
        "\n",
        "#--model = JSMRNN(1, cfg[\"model_params\"][\"n_hidden\"], cfg[\"model_params\"][\"n_layers\"]).to(device)\n",
        "model = JSMCNN().to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=cfg[\"model_params\"][\"lr\"]) \n",
        "\n",
        "# load weight if there is a pretrained model\n",
        "weight_path = cfg[\"model_params\"][\"weight_path\"]\n",
        "if weight_path != '':\n",
        "  model_state = torch.load(weight_path, map_location=device)\n",
        "  model.load_state_dict(model_state['state_dict'])\n",
        "  optimizer.load_state_dict(model_state['optimizer'])\n",
        "  iteration = model_state['iteration']\n",
        "else:\n",
        "  iteration = 0\n",
        "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
        "#--scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOhsRbXKNFo0",
        "outputId": "d8153a9b-44bc-41f3-9380-6e97a760ed7f"
      },
      "source": [
        "if cfg[\"model_params\"][\"train\"]:\n",
        "    progress_bar = tqdm( range(iteration, iteration+cfg[\"train_params\"][\"max_num_steps\"]))\n",
        "    losses_train = []\n",
        "    acc_train = []\n",
        "    iterations = []\n",
        "    metrics = []\n",
        "    times = []\n",
        "    model_name = cfg[\"model_params\"][\"model_name\"]\n",
        "    start = time.time()\n",
        "\n",
        "    #--h = model.init_hidden(cfg[\"train_params\"][\"batch_size\"])\n",
        "    tr_it = iter(train_dataloader)\n",
        "    epoch = 0\n",
        "    for i in progress_bar:\n",
        "        try:\n",
        "            x_data, y_data = next(tr_it)\n",
        "        except StopIteration:\n",
        "            epoch += 1\n",
        "            #print(f\"epoch: {epoch}\")\n",
        "            tr_it = iter(train_dataloader)\n",
        "            x_data, y_data = next(tr_it)\n",
        "        \n",
        "        #--if x_data.shape[0] != cfg[\"train_params\"][\"batch_size\"]:\n",
        "        #--  print(\"break\")\n",
        "        #--  break\n",
        "\n",
        "        model.train()\n",
        "        torch.set_grad_enabled(True)\n",
        "\n",
        "        #Move data to device\n",
        "        #--inputs = x_data.to(device).unsqueeze(-1)\n",
        "        inputs = x_data.to(device)\n",
        "        targets = y_data.to(device)\n",
        "        \n",
        "        #Forward model\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        #--h = tuple([each.data for each in h])\n",
        "        \n",
        "        #--model.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        #output, h = model(inputs, h)\n",
        "        output = model(inputs).view(targets.shape)\n",
        "  \n",
        "        loss = criterion(output, targets)\n",
        "        acc = binary_acc(output, targets)\n",
        "        \n",
        "        \n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        #n.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # step the scheduler\n",
        "        #--scheduler.step()\n",
        "\n",
        "        losses_train.append(loss.item())\n",
        "        acc_train.append(acc.item())\n",
        "\n",
        "        progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)} \\\n",
        "        | Acc: {acc.item()} Acc(avg): {np.mean(acc_train)}\")\n",
        "\n",
        "        if ((i != 0) and (i % cfg['train_params']['checkpoint_every_n_steps'] == 0)):\n",
        "          state = {\n",
        "                  'iteration': i + 1,\n",
        "                  'state_dict': model.state_dict(),\n",
        "                  'optimizer': optimizer.state_dict(),\n",
        "                  #'scheduler': scheduler,\n",
        "                }  \n",
        "          #torch.save(state, f'/content/drive/My Drive/colab/{cfg[\"model_params\"][\"model_architecture\"]}_model_state_{i}.pth')  \n",
        "          iterations.append(i)\n",
        "          metrics.append(np.mean(losses_train))\n",
        "          times.append((time.time()-start)/60)\n",
        "\n",
        "          losses_valid = []\n",
        "          acc_valid = []\n",
        "\n",
        "          for x_data, y_data in  iter(valid_dataloader):\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "              inputs = x_data.to(device)\n",
        "              targets = y_data.to(device)\n",
        "\n",
        "              output = model(inputs).view(targets.shape)\n",
        "              loss = criterion(output, targets)\n",
        "              acc = binary_acc(output, targets)\n",
        "\n",
        "              losses_valid.append(loss.item())\n",
        "              acc_valid.append(acc.item())\n",
        "          print(f\"\\n\\n valid loss(avg): {np.mean(losses_valid)} | valid Acc(avg): {np.mean(acc_valid)}\\n\")  \n",
        "    results = pd.DataFrame({\"iterations\": iterations, 'metrics (avg)': metrics, 'elapsed time (min)': times})\n",
        "    results.to_csv(f'{model_name}_{cfg[\"train_params\"][\"max_num_steps\"]}.csv', index=False)\n",
        "    print(f\"Total training time is {(time.time()-start)/60} mins\")\n",
        "    print(results.head())\n",
        "    state = {\n",
        "                  'iteration': i + 1,\n",
        "                  'state_dict': model.state_dict(),\n",
        "                  'optimizer': optimizer.state_dict(),\n",
        "                  #'scheduler': scheduler,\n",
        "                }  \n",
        "    torch.save(state, f'/content/drive/My Drive/colab/{cfg[\"model_params\"][\"model_architecture\"]}_model_state_{i}.pth')  \n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6609429121017456 loss(avg): 0.6612303058306376         | Acc: 57.0 Acc(avg): 57.0:   0%|          | 3/10000 [00:02<5:02:16,  1.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " valid loss(avg): 0.6602828368848684 | valid Acc(avg): 56.93877551020408\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6537613868713379 loss(avg): 0.6597386248636651         | Acc: 58.0 Acc(avg): 57.166250624063906:  20%|██        | 2003/10000 [02:21<42:19,  3.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " valid loss(avg): 0.6562619233617977 | valid Acc(avg): 57.38775510204081\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6550287008285522 loss(avg): 0.6576679552440996         | Acc: 59.0 Acc(avg): 57.41508491508492:  40%|████      | 4003/10000 [04:38<30:54,  3.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " valid loss(avg): 0.6525517166877279 | valid Acc(avg): 57.816326530612244\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6516958475112915 loss(avg): 0.6557783198646511         | Acc: 59.0 Acc(avg): 57.63607594936709:  60%|██████    | 6003/10000 [06:54<20:29,  3.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " valid loss(avg): 0.6487411357918564 | valid Acc(avg): 58.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6401795148849487 loss(avg): 0.654041764111831         | Acc: 58.0 Acc(avg): 57.8452023988006:  80%|████████  | 8003/10000 [09:11<10:12,  3.26it/s] "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " valid loss(avg): 0.6467127812152006 | valid Acc(avg): 58.42857142857143\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss: 0.6501681804656982 loss(avg): 0.6524599515080451         | Acc: 59.0 Acc(avg): 58.0275: 100%|██████████| 10000/10000 [11:25<00:00, 14.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total training time is 11.428395140171052 mins\n",
            "   iterations  metrics (avg)  elapsed time (min)\n",
            "0       10000       0.660205            0.003929\n",
            "1       12000       0.659743            2.320475\n",
            "2       14000       0.657671            4.597363\n",
            "3       16000       0.655782            6.873300\n",
            "4       18000       0.654046            9.154548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iu6DcUsRdO1"
      },
      "source": [
        "**Hyperparameter tuning:** finding the optimal model settings: training a number of models with different hyperparameters to find the best performer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEkPnoM6zLcT"
      },
      "source": [
        "# **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIjcz14spSCF"
      },
      "source": [
        "#Example Test Prediction Analysis\r\n",
        "example_test = pd.read_csv('/content/example_test.csv')\r\n",
        "example_test = example_test.query('weight > 0').reset_index(drop = True)\r\n",
        "example_test[features] = example_test[features].fillna(method = 'ffill').fillna(method = 'bfill').fillna(0)\r\n",
        "\r\n",
        "test_features = torch.tensor(example_test[features].values.astype(np.float32)).to(device)\r\n",
        "\r\n",
        "model.eval()\r\n",
        "with torch.no_grad():\r\n",
        "  y_test_pred = model(test_features)\r\n",
        "  y_test_pred = torch.sigmoid(y_test_pred)\r\n",
        "  y_pred_tag = torch.round(y_test_pred)\r\n",
        "  y_pred_tag = y_test_pred.cpu().numpy()\r\n",
        "\r\n",
        "print(y_pred_tag.min())\r\n",
        "print(y_pred_tag.max())\r\n",
        "print(y_pred_tag.mean())\r\n",
        "print(y_pred_tag.std())\r\n",
        "\r\n",
        "plt.hist(y_pred_tag, bins = 100)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xvrkICCpR17"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1UJNOdAzLcU"
      },
      "source": [
        "# We impute the missing values with the medians\n",
        "def fillna_npwhere(array, values):\n",
        "    if np.isnan(array.sum()):\n",
        "        array = np.where(np.isnan(array), values, array)\n",
        "    return array\n",
        "\n",
        "import janestreet\n",
        "env = janestreet.make_env() # initialize the environment\n",
        "iter_test = env.iter_test() # an iterator which loops over the test set\n",
        "\n",
        "for (test_df, sample_prediction_df) in iter_test:\n",
        "    wt = test_df.iloc[0].weight\n",
        "    if(wt == 0):\n",
        "        sample_prediction_df.action = 0 \n",
        "    else:\n",
        "        sample_prediction_df.action = np.where(clf.predict(xgb.DMatrix(pca.transform(scaler.transform(fillna_npwhere(test_df[features].values,train_median[features].values)))))>=0.5,1,0).astype(int)\n",
        "    env.predict(sample_prediction_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgdDTDvCVxEO"
      },
      "source": [
        "print(pred_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z49DctevzLcf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNQD1hm-zLci"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}